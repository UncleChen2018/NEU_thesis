{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94598854-b2b2-4c91-8ea3-ed9ddca2ff0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for london_smart_meters_with_missing already exported. Skipping...\n",
      "Data for smart already exported. Skipping...\n",
      "Data for sceaux already exported. Skipping...\n",
      "Data for LOOP_SEATTLE already exported. Skipping...\n",
      "Data for elecdemand already exported. Skipping...\n",
      "Data for traffic_hourly already exported. Skipping...\n",
      "Data for elf already exported. Skipping...\n",
      "Data for subseasonal_precip already exported. Skipping...\n",
      "Data for solar_power already exported. Skipping...\n",
      "Data for wind_power already exported. Skipping...\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def load_and_transform_subsets(dataset_name, subset_names, export_dir, split=\"train\"):\n",
    "    all_transformed_series = {}\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "    for subset_name in subset_names:\n",
    "        export_path = os.path.join(export_dir, f\"{subset_name}.csv\")\n",
    "        if os.path.exists(export_path):\n",
    "            print(f\"Data for {subset_name} already exported. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Load the dataset for the given subset\n",
    "        dataset = load_dataset(dataset_name, subset_name, split=split)\n",
    "        df = dataset.to_pandas()\n",
    "\n",
    "        # Get the first time series formatted DataFrame\n",
    "        expanded_series = expand_time_series(df, subset_name)\n",
    "        if expanded_series is not None:\n",
    "            all_transformed_series[subset_name] = expanded_series\n",
    "            # Save the series to a CSV file\n",
    "            expanded_series.to_csv(export_path, index=False, header=False)\n",
    "            print(f\"Exported {export_path}\")\n",
    "\n",
    "    return all_transformed_series\n",
    "\n",
    "\n",
    "def expand_time_series(df, subset_name):\n",
    "    for index, row in df.iterrows():\n",
    "        start = pd.to_datetime(row[\"start\"])\n",
    "        freq = row[\"freq\"]\n",
    "        target = np.array(row[\"target\"])\n",
    "\n",
    "        if target.ndim == 2:\n",
    "            target = target[:, 0]  # Select the first column only for simplicity\n",
    "\n",
    "        dates = pd.date_range(start=start, periods=len(target), freq=freq)\n",
    "        return pd.Series(data=target, index=dates)  # Return the first series\n",
    "\n",
    "    return None  # Return None if no data\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "dataset_name = \"Salesforce/lotsa_data\"\n",
    "subset_names = [\n",
    "    #\"bdg-2_fox\",\n",
    "    #\"bdg-2_rat\",\n",
    "    #\"bdg-2_bear\",\n",
    "    \"london_smart_meters_with_missing\",\n",
    "    \"smart\",\n",
    "    \"sceaux\",\n",
    "    # \"largest\",  # too large\n",
    "    #\"PEMS03\",\n",
    "    #\"PEMS07\",\n",
    "    #\"PEMS_BAY\",\n",
    "    #\"LOS_LOOP\",\n",
    "    \"LOOP_SEATTLE\",\n",
    "    #\"oikolab_weather\",\n",
    "    \"elecdemand\",\n",
    "    \"traffic_hourly\",\n",
    "    #\"saugeenday\",\n",
    "    \"elf\",\n",
    "    \"subseasonal_precip\",\n",
    "    #'solar_power',\n",
    "    #'wind_power'\n",
    "\n",
    "\n",
    "]\n",
    "export_dir = \"experiment_export_data\"  # Set your custom directory name here\n",
    "\n",
    "# Load and transform data\n",
    "transformed_data = load_and_transform_subsets(dataset_name, subset_names, export_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de6f6973-40e5-44a8-8e3d-24726b927cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def analyze_data_files(directory, subset_order):\n",
    "    summary_data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            subset_name = filename[:-4]  # Remove the \".csv\" from the filename\n",
    "            file_size = os.path.getsize(file_path)\n",
    "\n",
    "            # Load the CSV file, assuming no headers as per your specifications\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "            series_length = len(df)\n",
    "\n",
    "            if not df.empty:\n",
    "                # Assume the first column contains the data\n",
    "                column = df.iloc[:, 0].astype(\n",
    "                    str\n",
    "                )  # Ensure all data is treated as string\n",
    "                # Calculate the number of decimal places\n",
    "                decimals = column.apply(\n",
    "                    lambda x: len(x.split(\".\")[1]) if \".\" in x else 0\n",
    "                )\n",
    "                precision_counts = decimals.value_counts()\n",
    "                precision_proportions = (precision_counts / series_length * 100).round(\n",
    "                    2\n",
    "                )\n",
    "\n",
    "                # Most common precision and its proportion\n",
    "                most_common_precision = precision_counts.idxmax()\n",
    "                most_common_proportion = precision_proportions[most_common_precision]\n",
    "\n",
    "                # Average precision\n",
    "                average_precision = (decimals.sum() / series_length).round(2)\n",
    "            else:\n",
    "                most_common_precision = 0\n",
    "                most_common_proportion = 0.0\n",
    "                average_precision = 0.0\n",
    "\n",
    "            # Collect data into dictionary\n",
    "            summary_data.append(\n",
    "                {\n",
    "                    \"Subset Name\": subset_name,\n",
    "                    \"File Size (bytes)\": file_size,\n",
    "                    \"Series Length\": series_length,\n",
    "                    \"Most Common Precision\": most_common_precision,\n",
    "                    \"Most Common Precision Proportion (%)\": most_common_proportion,\n",
    "                    \"Average Precision\": average_precision,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # Create DataFrame from collected data\n",
    "    df_summary = pd.DataFrame(summary_data)\n",
    "\n",
    "    # Ensure the order matches your subset_names list\n",
    "    df_summary.set_index(\"Subset Name\", inplace=True)\n",
    "    df_summary = df_summary.reindex(subset_order).reset_index()\n",
    "\n",
    "    return df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2c70013-f783-4d34-bb97-a0ef8c5db861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Subset Name  File Size (bytes)  Series Length  \\\n",
      "0  london_smart_meters_with_missing             140896          23904   \n",
      "1                             smart             267583          25919   \n",
      "2                            sceaux             328246          34223   \n",
      "3                      LOOP_SEATTLE            1003466         105120   \n",
      "4                        elecdemand             167219          17520   \n",
      "5                    traffic_hourly             119719          17376   \n",
      "6                               elf             211782          21792   \n",
      "7                subseasonal_precip             109296          11323   \n",
      "8                       solar_power           33781822        7397222   \n",
      "9                        wind_power           36202451        7397147   \n",
      "\n",
      "   Most Common Precision  Most Common Precision Proportion (%)  \\\n",
      "0                      3                                 90.50   \n",
      "1                      7                                 49.70   \n",
      "2                      7                                 40.77   \n",
      "3                      6                                 59.17   \n",
      "4                      7                                 58.92   \n",
      "5                      4                                 89.93   \n",
      "6                      4                                 86.70   \n",
      "7                      6                                 46.15   \n",
      "8                      1                                100.00   \n",
      "9                      1                                100.00   \n",
      "\n",
      "   Average Precision  \n",
      "0               2.89  \n",
      "1               7.32  \n",
      "2               6.59  \n",
      "3               5.55  \n",
      "4               6.54  \n",
      "5               3.89  \n",
      "6               3.85  \n",
      "7               5.74  \n",
      "8               1.00  \n",
      "9               1.00  \n"
     ]
    }
   ],
   "source": [
    "directory = export_dir  # Specify your data directory here\n",
    "summary_df = analyze_data_files(directory, subset_names)\n",
    "print(summary_df)\n",
    "summary_df.to_csv(\"summary_df.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
